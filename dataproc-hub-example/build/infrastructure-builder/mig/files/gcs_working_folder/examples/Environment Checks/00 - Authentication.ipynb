{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "### Runs this to start from scratch\nBoth should return an error if no credentials were previously set and your are using the service account of the instance."}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[1;31mERROR:\u001b[0m (gcloud.auth.revoke) Cannot revoke GCE-provided credentials.\n"}], "source": "!gcloud auth revoke --quiet"}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[1;31mERROR:\u001b[0m (gcloud.auth.application-default.revoke) Application Default Credentials have not been set up, nothing was revoked.\n"}], "source": "!gcloud auth application-default revoke --quiet"}, {"cell_type": "markdown", "metadata": {}, "source": "### Authentication"}, {"cell_type": "markdown", "metadata": {}, "source": "1. **As a developer, I want to interact with GCP via gcloud.**\n\n    ```gcloud auth login``` (run from a Notebook terminal)\n\n    This obtains your credentials via a web flow and stores them in ```/root/.config/gcloud/credentials.db``` and for backward compatibility in ```/root/.config/gcloud/legacy_credentials/[YOUR_EMAIL]/adc.json```\n\n    Now:\n    - **gcloud** commands runs from the Notebook's cells finds your credentials automatically. \n    - **Other code or SDK** (Python, Java,...) not automatically picks up those credentials.\n\n    Reference: https://cloud.google.com/sdk/gcloud/reference/auth/login\n\n1. **As a developer, I want my code to interact with GCP via SDK.**\n\n    ```gcloud auth application-default login``` (run using the GCP option in the navigation menu)\n\n    This obtains your credentials via a web flow and stores them in ```/root/.config/gcloud/application_default_credentials.json```. \n\n    Now:\n    - **Other code or SDK** (Python, Java,...) finds the credentials automatically. \n    - Can run code locally which would normally run on a server without the need of a credentials file.\n\n    Reference: https://cloud.google.com/sdk/gcloud/reference/auth/application-default/login\n\n\nFor more information, you can read the Google documentation or this excellent [blog post](https://jpassing.com/2020/01/14/google-application-default-credentials-vs-your-personal-gcloud-credentials/)."}, {"cell_type": "markdown", "metadata": {}, "source": "#### Authenticate code running in the Notebook"}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [], "source": "# General\nimport google.auth\ncredentials, project_id = google.auth.default()"}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [], "source": "# Transparent for google.cloud libraries\nfrom google.cloud import bigquery\nclient = bigquery.Client()"}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [{"data": {"text/plain": "{'token': None,\n 'expiry': None,\n '_scopes': None,\n '_service_account_email': 'default'}"}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": "# If you try to run a query, this gets updated with values.\nclient.__dict__['_credentials'].__dict__"}, {"cell_type": "markdown", "metadata": {}, "source": "---\n**NOTE**\n\nFor BigQuery, if you run a query using the following, your identity should have the following IAM roles or similar:\n- *roles/bigquery.jobUser* (Lower resource is Project) that includes the *bigquery.jobs.create* permission.\n- *roles/bigquery.dataViewer* (Lower resource is Dataset) that includes *bigquery.tables.getData* permission.\n\n```py\nquery_job = client.query(QUERY) \nrows = query_job.result()\n```\n\n---"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Authenticate Spark\nYou can authenticate Spark using the credentials file or its content. Although you could use the file directly, workers would not have it locally because ```gcloud auth application-default login``` runs only for the Master. It means that the application_default_credentials.json file is only created on the Master node.\n\nWe have 3 options:\n\n- **Option 1 [Recommended]: Read the file and pass the value as a string.**\n- Option 2: Have the add-on to write the file to the master and workers. Requires proper permissions.\n- Option 3: Manually copy the file using a gcloud scp for example. Requires proper firewall access."}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[32m\nSpark is now authenticated on this Master node.\n\u001b[0m\n"}], "source": "import base64\n\nCREDENTIALS_FILE = \"/root/.config/gcloud/application_default_credentials.json\"\n\ndef get_credentials_text():\n    if not os.path.isfile(CREDENTIALS_FILE):\n        print(\"\\x1b[31m\\nNo credentials defined. Run gcloud auth application-default login.\\n\\x1b[0m\")\n        return\n    \n    return open(CREDENTIALS_FILE, \"r\").read()\n\ncredentials_txt = get_credentials_text()\ncredentials_b64 = base64.b64encode(credentials_txt.encode('utf-8')).decode('utf-8')\n\n# Can not have both credentialsFile and credentials set.\nspark.conf.unset(\"credentialsFile\")\nspark.conf.set(\"credentials\", credentials_b64)\n\nprint(\"\\x1b[32m\\nSpark is now authenticated on this Master node.\\n\\x1b[0m\")"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.10"}}, "nbformat": 4, "nbformat_minor": 4}